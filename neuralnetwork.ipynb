{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sample of Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, out_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, out_size)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x=F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris_dataset = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_dataset.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_dataset.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three types of iris flower and data include four data: sepal length, sepal width, petal length, petal width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try to classify iris type from these data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first, separate train and test data. Train data is used to fitting the model and test data is used to evaluate the model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(iris_dataset.data, iris_dataset.target, test_size=0.2, stratify=iris_dataset.target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = torch.tensor(train_X, dtype=torch.float32)\n",
    "test_X = torch.tensor(test_X, dtype=torch.float32)\n",
    "train_y = torch.tensor(train_y, dtype=torch.int64)\n",
    "test_y = torch.tensor(test_y, dtype=torch.int64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, very simple optimization scheme. Using each data one by one and optimize the parameters in network every steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of epoch 0 loss 1.1787612438201904\n",
      "number of epoch 100 loss 0.07345173507928848\n",
      "number of epoch 200 loss 0.05522734299302101\n",
      "number of epoch 300 loss 0.04852501302957535\n",
      "number of epoch 400 loss 0.04449308291077614\n",
      "number of epoch 500 loss 0.042108092457056046\n",
      "number of epoch 600 loss 0.04093480482697487\n",
      "number of epoch 700 loss 0.040312256664037704\n",
      "number of epoch 800 loss 0.03995087370276451\n",
      "number of epoch 900 loss 0.03966950625181198\n"
     ]
    }
   ],
   "source": [
    "model=Net(4, 100, 3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    out=model(train_X)\n",
    "    loss=criterion(out, train_y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        print('number of epoch', epoch, 'loss', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_out=model(test_X)\n",
    "_, predict_y = torch.max(predict_out, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 2, 1, 1, 0, 1, 0, 0, 2, 1, 2, 2, 2, 1, 0, 0, 0, 1, 1, 2, 0, 2, 1, 2,\n",
       "         2, 1, 1, 0, 2, 0]),\n",
       " tensor([0, 2, 1, 1, 0, 1, 0, 0, 2, 1, 2, 2, 2, 1, 0, 0, 0, 1, 1, 2, 0, 2, 1, 2,\n",
       "         2, 1, 1, 0, 2, 0]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y, predict_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 100.0 percent\n"
     ]
    }
   ],
   "source": [
    "n_test=len(test_X)\n",
    "accuracy=(predict_y==test_y).sum().item()/n_test\n",
    "print('accuracy is {} percent'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally, to make the optimization more stable, we use mini-batch learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of epoch 0 loss 0.5538369417190552\n",
      "number of epoch 100 loss 0.0065150754526257515\n",
      "number of epoch 200 loss 0.13144288957118988\n",
      "number of epoch 300 loss 0.10834857076406479\n",
      "number of epoch 400 loss 0.02163071371614933\n",
      "number of epoch 500 loss 0.03838806226849556\n",
      "number of epoch 600 loss 0.005226876121014357\n",
      "number of epoch 700 loss 0.17277060449123383\n",
      "number of epoch 800 loss 0.21886806190013885\n",
      "number of epoch 900 loss 0.0022180473897606134\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(train_X, train_y)\n",
    "test_dataset = TensorDataset(test_X, test_y)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=10, shuffle=False)\n",
    "\n",
    "model=Net(4, 100, 3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    for X, y in train_dataloader:\n",
    "        out=model(X)\n",
    "        loss=criterion(out, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        print('number of epoch', epoch, 'loss', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 100.0 percent\n"
     ]
    }
   ],
   "source": [
    "n_test=len(test_X)\n",
    "accuracy=(predict_y==test_y).sum().item()/n_test\n",
    "print('accuracy is {} percent'.format(accuracy*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
